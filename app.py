# -*- coding: utf-8 -*-
"""
DART ìë™ ë‹¤ìš´ë¡œë” (Streamlit, ì•ˆì •í™” ë²„ì „)
- íšŒì‚¬ ê²€ìƒ‰(ì •í™•ì¼ì¹˜ ìš°ì„  + ë¶€ë¶„ì¼ì¹˜)
- ì—°ë„ë³„ ê³µì‹œ ëª©ë¡ ìˆ˜ì§‘
- ê° ê³µì‹œ ZIP ë‹¤ìš´ë¡œë“œ â†’ ë¬¶ìŒ ZIPìœ¼ë¡œ ì œê³µ
- ZIP íŒŒì¼ëª…: ì œì¶œì¼_ë³´ê³ ì„œëª…_ì ‘ìˆ˜ë²ˆí˜¸.zip
- ìš”ì•½(ì—‘ì…€/CSV) + DART ë°”ë¡œê°€ê¸° ë§í¬ í¬í•¨
- ì•ˆì •í™”:
  * corpCode.xmlì´ ZIPì´ ì•„ë‹ ë•Œ ì›ì¸ ë©”ì‹œì§€ ë…¸ì¶œ
  * selectboxì— 'ë ˆì½”ë“œ(dict) ìì²´' ì‚¬ìš© + index=None (ì²« í•­ëª© ìë™ì„ íƒ ë°©ì§€)
  * ìƒˆ ê²€ìƒ‰ ì‹œ ì´ì „ ì„ íƒê°’ ì´ˆê¸°í™”
"""

import os
import io
import re
import time
import zipfile
import requests
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional

import streamlit as st

# ==============================
# Streamlit Page Config
# ==============================
st.set_page_config(page_title="DART ìë™ ë‹¤ìš´ë¡œë”", page_icon="ğŸ“‘", layout="wide")
st.title("ğŸ“‘ DART ìë™ ë‹¤ìš´ë¡œë”")

# ==============================
# OpenDART Endpoints / Session
# ==============================
API_HOST = "https://opendart.fss.or.kr"
CORPCODE_API = f"{API_HOST}/api/corpCode.xml"
LIST_API    = f"{API_HOST}/api/list.json"
DOC_API     = f"{API_HOST}/api/document.xml"

S = requests.Session()
S.headers.update({"User-Agent": "dart-auto-downloader/streamlit/1.2"})

# ==============================
# Utils
# ==============================
def sanitize_filename(name: str) -> str:
    """Windows/macOS/Linux ê³µí†µ ì•ˆì „ íŒŒì¼ëª…ìœ¼ë¡œ ì •ë¦¬"""
    if not name:
        name = "unknown_report"
    bad = r'\\/:*?"<>|'
    for ch in bad:
        name = name.replace(ch, "_")
    name = "_".join(name.split())
    return name[:120]

def is_zip(content: bytes) -> bool:
    return len(content) > 4 and content[:4] == b"PK\x03\x04"

@st.cache_data(show_spinner=False)
def fetch_corp_master(api_key: str) -> pd.DataFrame:
    """ë²•ì¸ì½”ë“œ ë§ˆìŠ¤í„° ZIP(xml) ë‹¤ìš´ë¡œë“œ í›„ DataFrameìœ¼ë¡œ ë°˜í™˜ (ìºì‹œ)
       - ì‘ë‹µì´ ZIPì´ ì•„ë‹ ê²½ìš°, ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•´ ì•ˆë‚´
    """
    key = (api_key or "").strip()
    if not key:
        raise RuntimeError("API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    try:
        r = S.get(CORPCODE_API, params={"crtfc_key": key}, timeout=60)
    except requests.RequestException as e:
        raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")

    content = r.content or b""
    content_type = r.headers.get("Content-Type", "")
    if not (is_zip(content) or "zip" in content_type.lower()):
        # ZIPì´ ì•„ë‹ˆë©´ JSON/XML/HTMLì¼ ìˆ˜ ìˆìŒ â†’ ê°€ëŠ¥í•œ ë©”ì‹œì§€ ì¶”ì¶œ
        txt = ""
        try:
            txt = content.decode("utf-8", errors="ignore")
        except Exception:
            pass

        # JSON(status/message)
        try:
            import json
            j = json.loads(txt)
            status = j.get("status"); message = j.get("message")
            if status or message:
                raise RuntimeError(f"OpenDART ì˜¤ë¥˜(status={status}): {message}")
        except Exception:
            pass

        # XML(<message>..</message>)
        try:
            import xml.etree.ElementTree as ET
            root = ET.fromstring(txt)
            msg = root.findtext(".//message") or root.findtext(".//msg") or ""
            if msg.strip():
                raise RuntimeError(f"OpenDART ì˜¤ë¥˜: {msg.strip()}")
        except Exception:
            pass

        hint = f" (HTTP {r.status_code})" if r.status_code and r.status_code != 200 else ""
        if "html" in content_type.lower():
            raise RuntimeError(f"OpenDARTì—ì„œ ZIPì´ ì•„ë‹Œ HTML ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤{hint}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ API Key/í•œë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        raise RuntimeError("OpenDARTì—ì„œ ZIPì´ ì•„ë‹Œ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. API Key/ìš”ì²­ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ì •ìƒ ZIP ì²˜ë¦¬
    try:
        with zipfile.ZipFile(io.BytesIO(content)) as zf:
            with zf.open(zf.namelist()[0]) as fp:
                import xml.etree.ElementTree as ET
                root = ET.parse(fp).getroot()
    except zipfile.BadZipFile:
        raise RuntimeError("ë°›ì€ íŒŒì¼ì´ ZIP í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ API Keyë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        raise RuntimeError(f"ZIP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    rows = []
    for el in root.findall(".//list"):
        rows.append({
            "corp_code": el.findtext("corp_code") or "",
            "corp_name": el.findtext("corp_name") or "",
            "stock_code": el.findtext("stock_code") or "",
        })
    return pd.DataFrame(rows)

def search_companies(master: pd.DataFrame, query: str) -> pd.DataFrame:
    """íšŒì‚¬ëª… ê²€ìƒ‰ (ì •í™•ì¼ì¹˜ + ë¶€ë¶„ì¼ì¹˜ ë™ì‹œ í‘œì¶œ, ì •í™•ì¼ì¹˜ ìš°ì„ )"""
    q = (query or "").strip()
    if not q:
        return master.head(0)

    m = master.copy()
    m["__norm"] = m["corp_name"].fillna("").str.replace(r"\s+", "", regex=True)
    qn = re.sub(r"\s+", "", q)

    # ì •í™•ì¼ì¹˜
    mask_exact = m["__norm"].str.casefold() == qn.casefold()
    exact = m[mask_exact].copy()
    exact["__rank"] = 0

    # ë¶€ë¶„ì¼ì¹˜
    mask_part = m["__norm"].str.contains(re.escape(qn), case=False, regex=True)
    part = m[mask_part & (~mask_exact)].copy()
    part["__rank"] = 1

    # í•©ì¹˜ê³  ì •ë ¬ (ìƒì¥ì‚¬ ìš°ì„ )
    res = pd.concat([exact, part], ignore_index=True)
    res["__listed"] = res["stock_code"].fillna("").ne("")
    res = res.sort_values(by=["__rank", "__listed", "corp_name"], ascending=[True, False, True])
    return res.head(200).drop(columns=["__norm", "__rank", "__listed"], errors="ignore")

def fetch_list(api_key: str, corp_code: str, year: str) -> List[Dict]:
    """ì—°ë„ë³„ ê³µì‹œ ëª©ë¡ ìˆ˜ì§‘(list.json í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)"""
    out = []
    page_no = 1
    bgn_de = f"{year}0101"
    end_de = f"{year}1231"
    while True:
        params = {
            "crtfc_key": api_key,
            "corp_code": corp_code,
            "bgn_de": bgn_de,
            "end_de": end_de,
            "page_no": page_no,
            "page_count": 100,
        }
        r = S.get(LIST_API, params=params, timeout=60)
        r.raise_for_status()
        data = r.json()
        if data.get("status") != "000":
            raise RuntimeError(f"list.json ì˜¤ë¥˜: {data.get('message')}")
        items = data.get("list") or []
        out.extend(items)
        total = int((data.get("total_count") or 0))
        if len(out) >= total or not items:
            break
        page_no += 1
        time.sleep(0.08)  # API ì˜ˆì˜ìƒ ì•½ê°„ ëŒ€ê¸°
    return out

def download_zip_bytes(api_key: str, rcept_no: str) -> Optional[bytes]:
    """document.xml ZIP ì›ë¬¸(ë°”ì´íŠ¸) ë°˜í™˜"""
    params = {"crtfc_key": api_key, "rcept_no": rcept_no}
    r = S.get(DOC_API, params=params, timeout=60)
    content = r.content or b""
    if r.status_code == 200 and is_zip(content):
        return content
    return None

def make_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    buf.seek(0)
    return buf.read()

# ==============================
# Sidebar (ì…ë ¥)
# ==============================
st.sidebar.markdown("### âš™ï¸ ì„¤ì •")
api_key = st.sidebar.text_input(
    "OpenDART API Key",
    type="password",
    value=os.getenv("OPENDART_API_KEY", ""),
    help="https://opendart.fss.or.kr/ ì—ì„œ í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì…ë ¥í•˜ì„¸ìš”.",
).strip()

year_default = str(datetime.now().year)
year = st.sidebar.text_input("ë‹¤ìš´ë¡œë“œ ì—°ë„ (YYYY)", value=year_default)
query = st.sidebar.text_input("íšŒì‚¬ëª… ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜ ê°€ëŠ¥)", value="")
exact_only = st.sidebar.checkbox("ì •í™•íˆ ì¼ì¹˜í•œ íšŒì‚¬ë§Œ ë³´ê¸°", value=False)
run_search = st.sidebar.button("íšŒì‚¬ ê²€ìƒ‰")

# =======
