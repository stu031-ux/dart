# -*- coding: utf-8 -*-
"""
DART ìë™ ë‹¤ìš´ë¡œë” (Streamlit)
- íšŒì‚¬ ê²€ìƒ‰(ì •í™•ì¼ì¹˜ ìš°ì„  + ë¶€ë¶„ì¼ì¹˜)
- ì—°ë„ë³„ ê³µì‹œ ëª©ë¡ ìˆ˜ì§‘
- ê° ê³µì‹œ ZIP ë‹¤ìš´ë¡œë“œ â†’ ë¬¶ìŒ ZIPìœ¼ë¡œ ì œê³µ
- ZIP íŒŒì¼ëª…: ì œì¶œì¼_ë³´ê³ ì„œëª…_ì ‘ìˆ˜ë²ˆí˜¸.zip
- ìš”ì•½(ì—‘ì…€/CSV) + DART ë°”ë¡œê°€ê¸° ë§í¬ í¬í•¨
- SelectboxëŠ” 'í–‰(dict) ìì²´'ë¥¼ ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©í•´ ì˜¤ì„ íƒ ë°©ì§€
"""

import os
import io
import re
import time
import zipfile
import requests
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

import streamlit as st

# ==============================
# Config
# ==============================
st.set_page_config(page_title="DART ìë™ ë‹¤ìš´ë¡œë”", page_icon="ğŸ“‘", layout="wide")

API_HOST = "https://opendart.fss.or.kr"
CORPCODE_API = f"{API_HOST}/api/corpCode.xml"
LIST_API    = f"{API_HOST}/api/list.json"
DOC_API     = f"{API_HOST}/api/document.xml"

S = requests.Session()
S.headers.update({"User-Agent": "dart-auto-downloader/streamlit/1.1"})

# ==============================
# Utils
# ==============================
def sanitize_filename(name: str) -> str:
    """Windows/macOS/Linux ê³µí†µ ì•ˆì „ íŒŒì¼ëª…ìœ¼ë¡œ ì •ë¦¬"""
    if not name:
        name = "unknown_report"
    bad = r'\\/:*?"<>|'
    for ch in bad:
        name = name.replace(ch, "_")
    name = "_".join(name.split())
    return name[:120]

def is_zip(content: bytes) -> bool:
    return len(content) > 1000 and content[:4] == b"PK\x03\x04"

@st.cache_data(show_spinner=False)
def fetch_corp_master(api_key: str) -> pd.DataFrame:
    """ë²•ì¸ì½”ë“œ ë§ˆìŠ¤í„° ZIP(xml) ë‹¤ìš´ë¡œë“œ í›„ DataFrameìœ¼ë¡œ ë°˜í™˜ (ìºì‹œ)"""
    r = S.get(CORPCODE_API, params={"crtfc_key": api_key}, timeout=60)
    r.raise_for_status()
    with zipfile.ZipFile(io.BytesIO(r.content)) as zf:
        with zf.open(zf.namelist()[0]) as fp:
            import xml.etree.ElementTree as ET
            root = ET.parse(fp).getroot()
    rows = []
    for el in root.findall(".//list"):
        rows.append({
            "corp_code": el.findtext("corp_code") or "",
            "corp_name": el.findtext("corp_name") or "",
            "stock_code": el.findtext("stock_code") or "",
        })
    return pd.DataFrame(rows)

def search_companies(master: pd.DataFrame, query: str) -> pd.DataFrame:
    """íšŒì‚¬ëª… ê²€ìƒ‰ (ì •í™•ì¼ì¹˜ + ë¶€ë¶„ì¼ì¹˜ ë™ì‹œ í‘œì¶œ, ì •í™•ì¼ì¹˜ ìš°ì„ )"""
    q = (query or "").strip()
    if not q:
        return master.head(0)

    m = master.copy()
    m["__norm"] = m["corp_name"].fillna("").str.replace(r"\s+", "", regex=True)
    qn = re.sub(r"\s+", "", q)

    # ì •í™•ì¼ì¹˜
    mask_exact = m["__norm"].str.casefold() == qn.casefold()
    exact = m[mask_exact].copy()
    exact["__rank"] = 0

    # ë¶€ë¶„ì¼ì¹˜
    mask_part = m["__norm"].str.contains(re.escape(qn), case=False, regex=True)
    part = m[mask_part & (~mask_exact)].copy()
    part["__rank"] = 1

    # í•©ì¹˜ê³  ì •ë ¬
    res = pd.concat([exact, part], ignore_index=True)
    res["__listed"] = res["stock_code"].fillna("").ne("")
    res = res.sort_values(by=["__rank", "__listed", "corp_name"], ascending=[True, False, True])
    return res.head(200).drop(columns=["__norm", "__rank", "__listed"], errors="ignore")

def fetch_list(api_key: str, corp_code: str, year: str) -> List[Dict]:
    """ì—°ë„ë³„ ê³µì‹œ ëª©ë¡ ìˆ˜ì§‘(list.json í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)"""
    out = []
    page_no = 1
    bgn_de = f"{year}0101"
    end_de = f"{year}1231"
    while True:
        params = {
            "crtfc_key": api_key,
            "corp_code": corp_code,
            "bgn_de": bgn_de,
            "end_de": end_de,
            "page_no": page_no,
            "page_count": 100,
        }
        r = S.get(LIST_API, params=params, timeout=60)
        r.raise_for_status()
        data = r.json()
        if data.get("status") != "000":
            raise RuntimeError(f"list.json ì˜¤ë¥˜: {data.get('message')}")
        items = data.get("list") or []
        out.extend(items)
        total = int((data.get("total_count") or 0))
        if len(out) >= total or not items:
            break
        page_no += 1
        time.sleep(0.08)  # API ì˜ˆì˜ìƒ ì•½ê°„ ì‰¬ì–´ì£¼ê¸°
    return out

def download_zip_bytes(api_key: str, rcept_no: str) -> Optional[bytes]:
    """document.xml ZIP ì›ë¬¸(ë°”ì´íŠ¸)"""
    params = {"crtfc_key": api_key, "rcept_no": rcept_no}
    r = S.get(DOC_API, params=params, timeout=60)
    content = r.content or b""
    if r.status_code == 200 and is_zip(content):
        return content
    return None

def make_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    buf.seek(0)
    return buf.read()

# ==============================
# Sidebar (ì…ë ¥)
# ==============================
st.sidebar.markdown("### âš™ï¸ ì„¤ì •")
api_key = st.sidebar.text_input(
    "OpenDART API Key",
    type="password",
    value=os.getenv("OPENDART_API_KEY", ""),
    help="https://opendart.fss.or.kr/ ì—ì„œ í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì…ë ¥í•˜ì„¸ìš”.",
)
year_default = str(datetime.now().year)
year = st.sidebar.text_input("ë‹¤ìš´ë¡œë“œ ì—°ë„ (YYYY)", value=year_default)
query = st.sidebar.text_input("íšŒì‚¬ëª… ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜ ê°€ëŠ¥)", value="")
exact_only = st.sidebar.checkbox("ì •í™•íˆ ì¼ì¹˜í•œ íšŒì‚¬ë§Œ ë³´ê¸°", value=False)
run_search = st.sidebar.button("íšŒì‚¬ ê²€ìƒ‰")

# ==============================
# Main Layout
# ==============================
st.title("ğŸ“‘ DART ìë™ ë‹¤ìš´ë¡œë”")
left, right = st.columns([1, 2])

with left:
    st.subheader("1) íšŒì‚¬ ê²€ìƒ‰ ë° ì„ íƒ")

    if api_key and run_search:
        try:
            master = fetch_corp_master(api_key)
            cand = search_companies(master, query)

            if exact_only and query.strip():
                qn = re.sub(r"\s+", "", query)
                cand = cand[
                    cand["corp_name"].fillna("").str.replace(r"\s+", "", regex=True).str.casefold()
                    == qn.casefold()
                ]

            if cand.empty:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                cand = cand.copy()
                cand["_label"] = cand.apply(
                    lambda r: f"{r['corp_name']} (corp_code:{r['corp_code']}"
                              + (f", ì£¼ì‹ì½”ë“œ:{r['stock_code']}" if r['stock_code'] else "")
                              + ")",
                    axis=1,
                )

                # âœ… ì¸ë±ìŠ¤ê°€ ì•„ë‹Œ 'ë ˆì½”ë“œ(dict) ìì²´'ë¥¼ ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©
                options = cand.to_dict("records")
                selected_row = st.selectbox(
                    "íšŒì‚¬ ì„ íƒ",
                    options=options,
                    format_func=lambda r: r["_label"],
                    key="company_selectbox",
                )

                # ì„ íƒ ê°’ì„ ì„¸ì…˜ì— ì €ì¥
                st.session_state["selected_company"] = {
                    "corp_code": selected_row["corp_code"],
                    "corp_name": selected_row["corp_name"],
                }

        except Exception as e:
            st.error(f"íšŒì‚¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    # ì„ íƒ í™•ì¸ ë°°ì§€
    if "selected_company" in st.session_state:
        sc = st.session_state["selected_company"]
        st.info(f"ì„ íƒëœ íšŒì‚¬: **{sc['corp_name']}**  (corp_code: `{sc['corp_code']}`)")

    # ì‹¤í–‰ ë²„íŠ¼
    run_download = st.button("2) ê³µì‹œ ZIP ë‹¤ìš´ë¡œë“œ & ìš”ì•½ ìƒì„±", use_container_width=True)

with right:
    st.subheader("ê²°ê³¼")
    table_ph = st.empty()
    dl_ph = st.empty()

# ==============================
# Action: ë‹¤ìš´ë¡œë“œ & ìš”ì•½ ìƒì„±
# ==============================
if run_download:
    if not api_key:
        st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif "selected_company" not in st.session_state:
        st.error("íšŒì‚¬ë¥¼ ë¨¼ì € ê²€ìƒ‰/ì„ íƒí•˜ì„¸ìš”.")
    elif not (len(year) == 4 and year.isdigit()):
        st.error("ì—°ë„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆ: 2024")
    else:
        corp_code = st.session_state["selected_company"]["corp_code"]
        corp_name = st.session_state["selected_company"]["corp_name"]

        try:
            with st.spinner("ê³µì‹œ ëª©ë¡ ìˆ˜ì§‘ ì¤‘â€¦"):
                items = fetch_list(api_key, corp_code, year)

            if not items:
                st.info("í•´ë‹¹ ì—°ë„ì— ìˆ˜ì§‘í•  ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = st.progress(0, text="ZIP ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘â€¦")
                total = len(items)

                summary = []
                bundle_buf = io.BytesIO()
                with zipfile.ZipFile(bundle_buf, "w", compression=zipfile.ZIP_DEFLATED) as bundle:
                    for i, it in enumerate(items, start=1):
                        rcept_no  = it.get("rcept_no", "")
                        rcept_dt  = it.get("rcept_dt", "")
                        report_nm = it.get("report_nm") or it.get("rpt_nm") or "unknown_report"

                        safe_zip_name = sanitize_filename(f"{rcept_dt}_{report_nm}_{rcept_no}") + ".zip"
                        content = download_zip_bytes(api_key, rcept_no)
                        if content:
                            bundle.writestr(safe_zip_name, content)
                            zip_saved = safe_zip_name
                        else:
                            zip_saved = f"{rcept_no}.zip (ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨)"

                        summary.append({
                            "ê¸°ì—…ëª…": corp_name,
                            "corp_code": corp_code,
                            "ë³´ê³ ì„œëª…": report_nm,
                            "ì ‘ìˆ˜ë²ˆí˜¸": rcept_no,
                            "ì œì¶œì¼": rcept_dt,
                            "ZIPì €ì¥íŒŒì¼": zip_saved,
                            "DARTë§í¬": f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}",
                        })

                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                        progress.progress(min(i / total, 1.0), text=f"ë‹¤ìš´ë¡œë“œ ì¤‘â€¦ ({i}/{total})")
                        time.sleep(0.06)  # API ì˜ˆì˜ìƒ ì‚´ì§ ëŒ€ê¸°

                # ìš”ì•½ í…Œì´ë¸”
                df = pd.DataFrame(summary).sort_values(["ì œì¶œì¼", "ë³´ê³ ì„œëª…"], ascending=[False, True])
                table_ph.dataframe(df, use_container_width=True)

                # ë‹¤ìš´ë¡œë“œ íŒŒì¼ë“¤
                excel_bytes = make_excel_bytes(df)
                csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
                bundle_buf.seek(0)
                zip_bundle_bytes = bundle_buf.read()

                with dl_ph:
                    c1, c2, c3 = st.columns(3)
                    with c1:
                        st.download_button(
                            "ğŸ“Š ìš”ì•½ ì—‘ì…€ ë°›ê¸°",
                            data=excel_bytes,
                            file_name=f"ê³µì‹œZIPìš”ì•½_{year}_{sanitize_filename(corp_name)}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                        )
                    with c2:
                        st.download_button(
                            "ğŸ“„ ìš”ì•½ CSV ë°›ê¸°",
                            data=csv_bytes,
                            file_name=f"ê³µì‹œZIPìš”ì•½_{year}_{sanitize_filename(corp_name)}.csv",
                            mime="text/csv",
                            use_container_width=True,
                        )
                    with c3:
                        st.download_button(
                            "ğŸ§¾ ZIP ì¼ê´„ ë‹¤ìš´ë¡œë“œ",
                            data=zip_bundle_bytes,
                            file_name=f"DART_{year}_{sanitize_filename(corp_name)}_{corp_code}_ZIPë¬¶ìŒ.zip",
                            mime="application/zip",
                            use_container_width=True,
                        )

                st.success(f"ì™„ë£Œ! ì´ {len(df)}ê±´ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
